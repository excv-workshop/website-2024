<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>eXCV Workshop at ECCV 2024</title>
    <link>https://excv-workshop.github.io/</link>
      <atom:link href="https://excv-workshop.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>eXCV Workshop at ECCV 2024</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© 2025 eXCV Workshop Organizers</copyright><lastBuildDate>Tue, 10 Sep 2024 22:02:03 +0200</lastBuildDate>
    <image>
      <url>https://excv-workshop.github.io/img/icon.png</url>
      <title>eXCV Workshop at ECCV 2024</title>
      <link>https://excv-workshop.github.io/</link>
    </image>
    
    <item>
      <title>&#34;Help Me Help the AI&#34;: Understanding How Explainability Can Support Human-AI Interaction</title>
      <link>https://excv-workshop.github.io/publication/help-me-help-the-ai-understanding-how-explainability-can-support-human-ai-interaction/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/help-me-help-the-ai-understanding-how-explainability-can-support-human-ai-interaction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>An Investigation on The Position Encoding in Vision-Based Dynamics Prediction</title>
      <link>https://excv-workshop.github.io/publication/an-investigation-on-the-position-encoding-in-vision-based-dynamics-prediction/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/an-investigation-on-the-position-encoding-in-vision-based-dynamics-prediction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Analyzing Vision Transformers for Image Classification in Class Embedding Space</title>
      <link>https://excv-workshop.github.io/publication/analyzing-vision-transformers-for-image-classification-in-class-embedding-space/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/analyzing-vision-transformers-for-image-classification-in-class-embedding-space/</guid>
      <description></description>
    </item>
    
    <item>
      <title>As large as it gets: Learning infinitely large Filters via Neural Implicit Functions in the Fourier Domain</title>
      <link>https://excv-workshop.github.io/publication/as-large-as-it-gets-learning-infinitely-large-filters-via-neural-implicit-functions-in-the-fourier-domain/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/as-large-as-it-gets-learning-infinitely-large-filters-via-neural-implicit-functions-in-the-fourier-domain/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Attribute Based Interpretable Evaluation Metrics for Generative Models</title>
      <link>https://excv-workshop.github.io/publication/attribute-based-interpretable-evaluation-metrics-for-generative-models/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/attribute-based-interpretable-evaluation-metrics-for-generative-models/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Can Biases in ImageNet Models Explain Generalization?</title>
      <link>https://excv-workshop.github.io/publication/can-biases-in-imagenet-models-explain-generalization/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/can-biases-in-imagenet-models-explain-generalization/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Concept-Based Explanations in Computer Vision: Where Are We and Where Could We Go?</title>
      <link>https://excv-workshop.github.io/publication/concept-based-explanations-in-computer-vision-where-are-we-and-where-could-we-go/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/concept-based-explanations-in-computer-vision-where-are-we-and-where-could-we-go/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Explanation Alignment: Quantifying the Correctness of Model Reasoning At Scale</title>
      <link>https://excv-workshop.github.io/publication/explanation-alignment-quantifying-the-correctness-of-model-reasoning-at-scale/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/explanation-alignment-quantifying-the-correctness-of-model-reasoning-at-scale/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Feature Contribution in Monocular Depth Estimation</title>
      <link>https://excv-workshop.github.io/publication/feature-contribution-in-monocular-depth-estimation/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/feature-contribution-in-monocular-depth-estimation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>From Flexibility to Manipulation: The Slippery Slope of XAI Evaluation</title>
      <link>https://excv-workshop.github.io/publication/from-flexibility-to-manipulation-the-slippery-slope-of-xai-evaluation/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/from-flexibility-to-manipulation-the-slippery-slope-of-xai-evaluation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Global Counterfactual Directions</title>
      <link>https://excv-workshop.github.io/publication/global-counterfactual-directions/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/global-counterfactual-directions/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Image-guided topic modeling for interpretable privacy classification</title>
      <link>https://excv-workshop.github.io/publication/image-guided-topic-modeling-for-interpretable-privacy-classification/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/image-guided-topic-modeling-for-interpretable-privacy-classification/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Integrating Local and Global Interpretability for Deep Concept-Based Reasoning Models</title>
      <link>https://excv-workshop.github.io/publication/integrating-local-and-global-interpretability-for-deep-concept-based-reasoning-models/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/integrating-local-and-global-interpretability-for-deep-concept-based-reasoning-models/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Interpretability benchmark for evaluating spatial misalignment of prototypical parts explanations</title>
      <link>https://excv-workshop.github.io/publication/interpretability-benchmark-for-evaluating-spatial-misalignment-of-prototypical-parts-explanations/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/interpretability-benchmark-for-evaluating-spatial-misalignment-of-prototypical-parts-explanations/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Localization-Guided Supervision for Robust Medical Image Classification by Vision Transformers</title>
      <link>https://excv-workshop.github.io/publication/localization-guided-supervision-for-robust-medical-image-classification-by-vision-transformers/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/localization-guided-supervision-for-robust-medical-image-classification-by-vision-transformers/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Network Inversion of Binarised Neural Nets</title>
      <link>https://excv-workshop.github.io/publication/network-inversion-of-binarised-neural-nets/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/network-inversion-of-binarised-neural-nets/</guid>
      <description></description>
    </item>
    
    <item>
      <title>PDiscoFormer: Relaxing Part Discovery Constraints with Vision Transformers</title>
      <link>https://excv-workshop.github.io/publication/pdiscoformer-relaxing-part-discovery-constraints-with-vision-transformers/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/pdiscoformer-relaxing-part-discovery-constraints-with-vision-transformers/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ProactiV: Studying Deep Learning Model Behavior under Input Transformations</title>
      <link>https://excv-workshop.github.io/publication/proactiv-studying-deep-learning-model-behavior-under-input-transformations/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/proactiv-studying-deep-learning-model-behavior-under-input-transformations/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pruning By Explaining Revisited: Optimizing Attribution Methods to Prune CNNs and Transformers</title>
      <link>https://excv-workshop.github.io/publication/pruning-by-explaining-revisited-optimizing-attribution-methods-to-prune-cnns-and-transformers/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/pruning-by-explaining-revisited-optimizing-attribution-methods-to-prune-cnns-and-transformers/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Q-SENN: Quantized Self-Explaining Neural Networks</title>
      <link>https://excv-workshop.github.io/publication/q-senn-quantized-self-explaining-neural-networks/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/q-senn-quantized-self-explaining-neural-networks/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Top-GAP: Integrating Size Priors in CNNs for more Interpretability, Robustness, and Bias Mitigation</title>
      <link>https://excv-workshop.github.io/publication/top-gap-integrating-size-priors-in-cnns-for-more-interpretability-robustness-and-bias-mitigation/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/top-gap-integrating-size-priors-in-cnns-for-more-interpretability-robustness-and-bias-mitigation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Visual Concept Connectome (VCC): Open World Concept Discovery and their Interlayer Connections in Deep Models</title>
      <link>https://excv-workshop.github.io/publication/visual-concept-connectome-vcc-open-world-concept-discovery-and-their-interlayer-connections-in-deep-models/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/visual-concept-connectome-vcc-open-world-concept-discovery-and-their-interlayer-connections-in-deep-models/</guid>
      <description></description>
    </item>
    
    <item>
      <title>VTCD: Understanding Video Transformers via Universal Concept Discovery</title>
      <link>https://excv-workshop.github.io/publication/vtcd-understanding-video-transformers-via-universal-concept-discovery/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/vtcd-understanding-video-transformers-via-universal-concept-discovery/</guid>
      <description></description>
    </item>
    
    <item>
      <title>What could go wrong? Discovering and describing failure modes in computer vision</title>
      <link>https://excv-workshop.github.io/publication/what-could-go-wrong-discovering-and-describing-failure-modes-in-computer-vision/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/what-could-go-wrong-discovering-and-describing-failure-modes-in-computer-vision/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
