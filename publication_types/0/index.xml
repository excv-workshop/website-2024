<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>0 | eXCV Workshop at ECCV 2024</title>
    <link>https://excv-workshop.github.io/publication_types/0/</link>
      <atom:link href="https://excv-workshop.github.io/publication_types/0/index.xml" rel="self" type="application/rss+xml" />
    <description>0</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© 2024 eXCV Workshop Organizers</copyright><lastBuildDate>Tue, 10 Sep 2024 22:02:03 +0200</lastBuildDate>
    <image>
      <url>https://excv-workshop.github.io/img/icon.png</url>
      <title>0</title>
      <link>https://excv-workshop.github.io/publication_types/0/</link>
    </image>
    
    <item>
      <title>An Investigation on The Position Encoding in Vision-Based Dynamics Prediction</title>
      <link>https://excv-workshop.github.io/publication/an-investigation-on-the-position-encoding-in-vision-based-dynamics-prediction/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/an-investigation-on-the-position-encoding-in-vision-based-dynamics-prediction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Concept-Based Explanations in Computer Vision: Where Are We and Where Could We Go?</title>
      <link>https://excv-workshop.github.io/publication/concept-based-explanations-in-computer-vision-where-are-we-and-where-could-we-go/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/concept-based-explanations-in-computer-vision-where-are-we-and-where-could-we-go/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Explanation Alignment: Quantifying the Correctness of Model Reasoning At Scale</title>
      <link>https://excv-workshop.github.io/publication/explanation-alignment-quantifying-the-correctness-of-model-reasoning-at-scale/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/explanation-alignment-quantifying-the-correctness-of-model-reasoning-at-scale/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Feature Contribution in Monocular Depth Estimation</title>
      <link>https://excv-workshop.github.io/publication/feature-contribution-in-monocular-depth-estimation/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/feature-contribution-in-monocular-depth-estimation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>From Flexibility to Manipulation: The Slippery Slope of XAI Evaluation</title>
      <link>https://excv-workshop.github.io/publication/from-flexibility-to-manipulation-the-slippery-slope-of-xai-evaluation/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/from-flexibility-to-manipulation-the-slippery-slope-of-xai-evaluation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Image-guided topic modeling for interpretable privacy classification</title>
      <link>https://excv-workshop.github.io/publication/image-guided-topic-modeling-for-interpretable-privacy-classification/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/image-guided-topic-modeling-for-interpretable-privacy-classification/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Integrating Local and Global Interpretability for Deep Concept-Based Reasoning Models</title>
      <link>https://excv-workshop.github.io/publication/integrating-local-and-global-interpretability-for-deep-concept-based-reasoning-models/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/integrating-local-and-global-interpretability-for-deep-concept-based-reasoning-models/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Localization-Guided Supervision for Robust Medical Image Classification by Vision Transformers</title>
      <link>https://excv-workshop.github.io/publication/localization-guided-supervision-for-robust-medical-image-classification-by-vision-transformers/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/localization-guided-supervision-for-robust-medical-image-classification-by-vision-transformers/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pruning By Explaining Revisited: Optimizing Attribution Methods to Prune CNNs and Transformers</title>
      <link>https://excv-workshop.github.io/publication/pruning-by-explaining-revisited-optimizing-attribution-methods-to-prune-cnns-and-transformers/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/pruning-by-explaining-revisited-optimizing-attribution-methods-to-prune-cnns-and-transformers/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Top-GAP: Integrating Size Priors in CNNs for more Interpretability, Robustness, and Bias Mitigation</title>
      <link>https://excv-workshop.github.io/publication/top-gap-integrating-size-priors-in-cnns-for-more-interpretability-robustness-and-bias-mitigation/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/top-gap-integrating-size-priors-in-cnns-for-more-interpretability-robustness-and-bias-mitigation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>What could go wrong? Discovering and describing failure modes in computer vision</title>
      <link>https://excv-workshop.github.io/publication/what-could-go-wrong-discovering-and-describing-failure-modes-in-computer-vision/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/what-could-go-wrong-discovering-and-describing-failure-modes-in-computer-vision/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
