<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>nonproceedings | eXCV Workshop at ECCV 2024</title>
    <link>https://excv-workshop.github.io/tags/nonproceedings/</link>
      <atom:link href="https://excv-workshop.github.io/tags/nonproceedings/index.xml" rel="self" type="application/rss+xml" />
    <description>nonproceedings</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© 2025 eXCV Workshop Organizers</copyright><lastBuildDate>Tue, 10 Sep 2024 22:02:03 +0200</lastBuildDate>
    <image>
      <url>https://excv-workshop.github.io/img/icon.png</url>
      <title>nonproceedings</title>
      <link>https://excv-workshop.github.io/tags/nonproceedings/</link>
    </image>
    
    <item>
      <title>&#34;Help Me Help the AI&#34;: Understanding How Explainability Can Support Human-AI Interaction</title>
      <link>https://excv-workshop.github.io/publication/help-me-help-the-ai-understanding-how-explainability-can-support-human-ai-interaction/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/help-me-help-the-ai-understanding-how-explainability-can-support-human-ai-interaction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Analyzing Vision Transformers for Image Classification in Class Embedding Space</title>
      <link>https://excv-workshop.github.io/publication/analyzing-vision-transformers-for-image-classification-in-class-embedding-space/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/analyzing-vision-transformers-for-image-classification-in-class-embedding-space/</guid>
      <description></description>
    </item>
    
    <item>
      <title>As large as it gets: Learning infinitely large Filters via Neural Implicit Functions in the Fourier Domain</title>
      <link>https://excv-workshop.github.io/publication/as-large-as-it-gets-learning-infinitely-large-filters-via-neural-implicit-functions-in-the-fourier-domain/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/as-large-as-it-gets-learning-infinitely-large-filters-via-neural-implicit-functions-in-the-fourier-domain/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Attribute Based Interpretable Evaluation Metrics for Generative Models</title>
      <link>https://excv-workshop.github.io/publication/attribute-based-interpretable-evaluation-metrics-for-generative-models/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/attribute-based-interpretable-evaluation-metrics-for-generative-models/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Can Biases in ImageNet Models Explain Generalization?</title>
      <link>https://excv-workshop.github.io/publication/can-biases-in-imagenet-models-explain-generalization/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/can-biases-in-imagenet-models-explain-generalization/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Global Counterfactual Directions</title>
      <link>https://excv-workshop.github.io/publication/global-counterfactual-directions/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/global-counterfactual-directions/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Interpretability benchmark for evaluating spatial misalignment of prototypical parts explanations</title>
      <link>https://excv-workshop.github.io/publication/interpretability-benchmark-for-evaluating-spatial-misalignment-of-prototypical-parts-explanations/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/interpretability-benchmark-for-evaluating-spatial-misalignment-of-prototypical-parts-explanations/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Network Inversion of Binarised Neural Nets</title>
      <link>https://excv-workshop.github.io/publication/network-inversion-of-binarised-neural-nets/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/network-inversion-of-binarised-neural-nets/</guid>
      <description></description>
    </item>
    
    <item>
      <title>PDiscoFormer: Relaxing Part Discovery Constraints with Vision Transformers</title>
      <link>https://excv-workshop.github.io/publication/pdiscoformer-relaxing-part-discovery-constraints-with-vision-transformers/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/pdiscoformer-relaxing-part-discovery-constraints-with-vision-transformers/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ProactiV: Studying Deep Learning Model Behavior under Input Transformations</title>
      <link>https://excv-workshop.github.io/publication/proactiv-studying-deep-learning-model-behavior-under-input-transformations/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/proactiv-studying-deep-learning-model-behavior-under-input-transformations/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Q-SENN: Quantized Self-Explaining Neural Networks</title>
      <link>https://excv-workshop.github.io/publication/q-senn-quantized-self-explaining-neural-networks/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/q-senn-quantized-self-explaining-neural-networks/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Visual Concept Connectome (VCC): Open World Concept Discovery and their Interlayer Connections in Deep Models</title>
      <link>https://excv-workshop.github.io/publication/visual-concept-connectome-vcc-open-world-concept-discovery-and-their-interlayer-connections-in-deep-models/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/visual-concept-connectome-vcc-open-world-concept-discovery-and-their-interlayer-connections-in-deep-models/</guid>
      <description></description>
    </item>
    
    <item>
      <title>VTCD: Understanding Video Transformers via Universal Concept Discovery</title>
      <link>https://excv-workshop.github.io/publication/vtcd-understanding-video-transformers-via-universal-concept-discovery/</link>
      <pubDate>Tue, 10 Sep 2024 22:02:03 +0200</pubDate>
      <guid>https://excv-workshop.github.io/publication/vtcd-understanding-video-transformers-via-universal-concept-discovery/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
